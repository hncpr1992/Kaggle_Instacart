{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will use Keras to implement a nueral network structure proposed by the paper <br>\n",
    "***Next Basket Recommendation with Neural Networks*** <br>\n",
    "http://ceur-ws.org/Vol-1441/recsys2015_poster15.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, merge, LSTM\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and define parameters and directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define constants and parameters\n",
    "INPUT_DIR = '../input/'\n",
    "TRANSFORM_DIR = \"../transform/\"\n",
    "OUTOUT_DIR = \"../output/\"\n",
    "PRIOR_DATA_FILE = TRANSFORM_DIR + 'orders_prior_merge.csv'\n",
    "TRAIN_DATA_FILE = TRANSFORM_DIR + 'orders_train_merge.csv'\n",
    "TEST_DATA_FILE = TRANSFORM_DIR + 'orders_test.csv'\n",
    "\n",
    "VALIDATION_SPLIT_RATIO = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-87593c568ace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# define constants and parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m MAX_ITEM = max(max(orders_train_merge[\"product_id\"].apply(lambda x:len(ast.literal_eval(x)))), \n\u001b[1;32m----> 9\u001b[1;33m                max(orders_prior_merge[\"product_id\"].apply(lambda x:len(ast.literal_eval(x)))))\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mPRE_BASKET\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morders_train_merge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morder_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morders_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morder_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peiran/anaconda3/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   2218\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2219\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2220\u001b[1;33m             \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:62658)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-87593c568ace>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# define constants and parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m MAX_ITEM = max(max(orders_train_merge[\"product_id\"].apply(lambda x:len(ast.literal_eval(x)))), \n\u001b[1;32m----> 9\u001b[1;33m                max(orders_prior_merge[\"product_id\"].apply(lambda x:len(ast.literal_eval(x)))))\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mPRE_BASKET\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morders_train_merge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morder_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morders_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morder_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peiran/anaconda3/lib/python3.5/ast.py\u001b[0m in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'malformed node or string: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peiran/anaconda3/lib/python3.5/ast.py\u001b[0m in \u001b[0;36m_convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load data\n",
    "orders_train_merge = pd.read_csv(TRAIN_DATA_FILE)\n",
    "orders_prior_merge = pd.read_csv(PRIOR_DATA_FILE)\n",
    "orders_test = pd.read_csv(TEST_DATA_FILE)\n",
    "products = pd.read_csv(INPUT_DIR+\"products.csv\")\n",
    "\n",
    "# define constants and parameters\n",
    "MAX_ITEM = max(max(orders_train_merge[\"product_id\"].apply(lambda x:len(ast.literal_eval(x)))), \n",
    "               max(orders_prior_merge[\"product_id\"].apply(lambda x:len(ast.literal_eval(x)))))\n",
    "PRE_BASKET = min(min(orders_train_merge.order_number), min(orders_test.order_number))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_dense = np.random.randint(100, 120)\n",
    "rate_drop_dense = 0.15 + np.random.rand() * 0.25\n",
    "\n",
    "STAMP = 'nn_%d_%.2f'%(num_dense, rate_drop_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get useful columns\n",
    "prior = orders_prior_merge[[\"order_id\",\"user_id\",\"product_id\"]]\n",
    "train = orders_train_merge[[\"order_id\",\"user_id\",\"product_id\"]]\n",
    "test = orders_test[[\"order_id\",\"user_id\"]]\n",
    "\n",
    "# create user_id dict\n",
    "train_usr_dict = dict.fromkeys(train.user_id)\n",
    "test_usr_dict = dict.fromkeys(test.user_id)\n",
    "\n",
    "# split train and test prior data\n",
    "prior_train = prior.ix[[x in train_usr_dict for x in list(prior.user_id)],:]\n",
    "prior_test = prior.ix[[x in test_usr_dict for x in list(prior.user_id)],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Validation split\n",
    "def split_train_val(data, val_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    val_set_size = int(len(data)*val_ratio)\n",
    "    val_indices = shuffled_indices[:val_set_size]\n",
    "    train_indices = shuffled_indices[val_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[val_indices]\n",
    "\n",
    "np.random.seed(1992)\n",
    "train_train, train_val = split_train_val(train, VALIDATION_SPLIT_RATIO)\n",
    "\n",
    "# create user_id dict\n",
    "train_train_usr_dict = dict.fromkeys(train_train.user_id)\n",
    "train_val_usr_dict = dict.fromkeys(train_val.user_id)\n",
    "\n",
    "# split train_train and train_val prior data\n",
    "prior_train_train = prior_train.ix[[x in train_train_usr_dict for x in list(prior_train.user_id)],:]\n",
    "prior_train_val = prior_train.ix[[x in train_val_usr_dict for x in list(prior_train.user_id)],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prior\n",
    "def get_pre_baskets(prior):\n",
    "    return prior.groupby(\"user_id\").tail(3)\n",
    "\n",
    "train_train_baskets = get_pre_baskets(prior_train_train)\n",
    "train_val_baskets = get_pre_baskets(prior_train_val)\n",
    "\n",
    "test_baskets = get_pre_baskets(prior_test)\n",
    "\n",
    "assert min(train_val_baskets.groupby(\"user_id\").apply(len)) == PRE_BASKET\n",
    "assert min(train_train_baskets.groupby(\"user_id\").apply(len)) == PRE_BASKET\n",
    "\n",
    "# extract sequence of items from pandas frame\n",
    "sequence_train_train = list(map(ast.literal_eval,train_train_baskets[\"product_id\"].tolist()))\n",
    "sequence_train_val = list(map(ast.literal_eval,train_val_baskets[\"product_id\"].tolist()))\n",
    "\n",
    "sequence_test = list(map(ast.literal_eval,test_baskets[\"product_id\"].tolist()))\n",
    "\n",
    "# pad all train and val with max items\n",
    "data_train_train = pad_sequences(sequence_train_train, maxlen=MAX_ITEM, padding='post', truncating='post')\n",
    "data_train_val = pad_sequences(sequence_train_val, maxlen=MAX_ITEM, padding='post', truncating='post')\n",
    "data_test = pad_sequences(sequence_test, maxlen=MAX_ITEM, padding='post', truncating='post')\n",
    "\n",
    "# extract sequence of items from pandas frame\n",
    "sequence_train_train = list(map(ast.literal_eval,train_train_baskets[\"product_id\"].tolist()))\n",
    "sequence_train_val = list(map(ast.literal_eval,train_val_baskets[\"product_id\"].tolist()))\n",
    "\n",
    "sequence_test = list(map(ast.literal_eval,test_baskets[\"product_id\"].tolist()))\n",
    "\n",
    "# pad all train and val with max items\n",
    "data_train_train = pad_sequences(sequence_train_train, maxlen=MAX_ITEM, padding='post', truncating='post')\n",
    "data_train_val = pad_sequences(sequence_train_val, maxlen=MAX_ITEM, padding='post', truncating='post')\n",
    "\n",
    "data_test = pad_sequences(sequence_test, maxlen=MAX_ITEM, padding='post', truncating='post')\n",
    "\n",
    "data_train_train_bs1 = data_train_train[0::3]\n",
    "data_train_train_bs2 = data_train_train[1::3]\n",
    "data_train_train_bs3 = data_train_train[2::3]\n",
    "\n",
    "data_train_val_bs1 = data_train_val[0::3]\n",
    "data_train_val_bs2 = data_train_val[1::3]\n",
    "data_train_val_bs3 = data_train_val[2::3]\n",
    "\n",
    "data_test_bs1 = data_test[0::3]\n",
    "data_test_bs2 = data_test[1::3]\n",
    "data_test_bs3 = data_test[2::3]\n",
    "\n",
    "label_sequence_train_train = list(map(ast.literal_eval,train_train[\"product_id\"].tolist()))\n",
    "label_sequence_train_val = list(map(ast.literal_eval,train_val[\"product_id\"].tolist()))\n",
    "\n",
    "data_train_train_one_user = np.concatenate([data_train_train_bs1,data_train_train_bs2,data_train_train_bs3], axis = 1)\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=products[\"product_id\"].tolist(), sparse_output=True)\n",
    "\n",
    "train_train_label = mlb.fit_transform(label_sequence_train_train)\n",
    "train_val_label = mlb.fit_transform(label_sequence_train_val)\n",
    "\n",
    "weight_val = np.ones(MAX_ITEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a mask for cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract all the purchase history of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create user buying history\n",
    "prior_sequence = list(map(ast.literal_eval,prior[\"product_id\"].tolist()))\n",
    "\n",
    "prior_usr = prior[\"user_id\"]\n",
    "\n",
    "usr_history = {k: [] for k in set(prior_usr)}  \n",
    "\n",
    "for i in range(len(prior_usr)):\n",
    "    usr_history[prior_usr[i]].extend(prior_sequence[i])\n",
    "\n",
    "usr_history_encode = [usr_history[x] for x in range(1, len(usr_history)+1)]\n",
    "\n",
    "del usr_history\n",
    "\n",
    "# create user list for train, val and test\n",
    "mlb = MultiLabelBinarizer(classes=range(1,49689), sparse_output=True)\n",
    "usr_history = mlb.fit_transform(usr_history_encode)\n",
    "\n",
    "train_train_usr = train_train_baskets.ix[0::3, \"user_id\"].values\n",
    "train_val_usr = train_val_baskets.ix[0::3, \"user_id\"].values\n",
    "test_usr = test_baskets.ix[0::3, \"user_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usr_history.shape\n",
    "\n",
    "len(train_train_usr)\n",
    "\n",
    "data_train_train_bs1.shape\n",
    "\n",
    "train_train_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete some data not used - for the purpose of saving memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del prior\n",
    "del train\n",
    "del test\n",
    "\n",
    "# create user_id dict\n",
    "del train_usr_dict\n",
    "del test_usr_dict\n",
    "\n",
    "# split train and test prior data\n",
    "del prior_train\n",
    "del prior_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "\n",
    "num_products = len(products)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the model graph\n",
    "product_embedding_layer = Embedding(input_dim=num_products,\n",
    "        output_dim=EMBEDDING_DIM,\n",
    "        embeddings_initializer='normal',\n",
    "        mask_zero=True,\n",
    "        input_length=3*MAX_ITEM,\n",
    "        trainable=True)\n",
    "\n",
    "# user_mask_layer = Embedding(input_dim=206209,\n",
    "#         output_dim=49688,\n",
    "#         weights=[usr_history],\n",
    "#         mask_zero=True,\n",
    "#         input_length=1,\n",
    "#         trainable=False)\n",
    "\n",
    "lstm_layer = LSTM(100)\n",
    "\n",
    "bs_1 = Input(shape=(3*MAX_ITEM,), dtype='int32')\n",
    "# bs_2 = Input(shape=(MAX_ITEM,), dtype='int32')\n",
    "# bs_3 = Input(shape=(MAX_ITEM,), dtype='int32')\n",
    "b_hist = Input(shape=(49688,), dtype='float32')\n",
    "\n",
    "\n",
    "embedded_bs_1 = product_embedding_layer(bs_1)\n",
    "lstm_out = lstm_layer(embedded_bs_1)\n",
    "# embedded_bs_2 = product_embedding_layer(bs_2)\n",
    "# embedded_bs_3 = product_embedding_layer(bs_3)\n",
    "# embedded_b_hist = user_mask_layer(u_id)\n",
    "\n",
    "# def embedding_mean(e):\n",
    "#     return K.mean(e, axis = 1)\n",
    "\n",
    "# embedded_bs_1_mean = Lambda(embedding_mean)(embedded_bs_1)\n",
    "# embedded_bs_2_mean = Lambda(embedding_mean)(embedded_bs_2)\n",
    "# embedded_bs_3_mean = Lambda(embedding_mean)(embedded_bs_3)\n",
    "\n",
    "# merged = concatenate([embedded_bs_1_mean, embedded_bs_2_mean, embedded_bs_3_mean])\n",
    "merged = BatchNormalization()(lstm_out)\n",
    "merged = Dropout(rate_drop_dense)(merged)\n",
    "merged = Dense(num_dense, kernel_initializer='normal', activation=\"relu\")(merged)\n",
    "\n",
    "preds = Dense(num_products-1, kernel_initializer='normal', activation='sigmoid')(merged)\n",
    "mask_preds = merge([preds, b_hist], mode='mul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile model \n",
    "model = Model(inputs=[bs_1, b_hist], outputs=mask_preds)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \\\n",
    "        optimizer='adam')\n",
    "print(STAMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set early stopping\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=3)  \n",
    "bst_model_path = OUTOUT_DIR + STAMP + '.h5' \n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "def batch_generator(data_train_train_one_user, user_dict, buy_history, label_mat, batch_size):\n",
    "    N = np.shape(label_mat)[0]\n",
    "    number_of_batches = N/batch_size\n",
    "    counter=0\n",
    "    shuffle_index = np.arange(N)\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    while True:\n",
    "        index_batch = shuffle_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        data_input = data_train_train_one_user[index_batch, :]\n",
    "        u_id = user_dict[index_batch]\n",
    "        b_hist_input = buy_history[u_id,:].todense()\n",
    "        label_input = np.asarray(label_mat[index_batch].todense())\n",
    "        counter += 1\n",
    "        yield([data_input, b_hist_input],label_input)\n",
    "        if (counter < number_of_batches):\n",
    "            np.random.shuffle(shuffle_index)\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(generator=batch_generator(\n",
    "                    data_train_train_one_user[0:1000], train_train_usr,\\\n",
    "                    usr_history, train_train_label[0:1000], 20), \\\n",
    "#                     validation_data=([data_train_train_bs1[0:1000], data_train_train_bs2[0:1000], \n",
    "#                                       data_train_train_bs3[0:1000]],  train_train_label[0:1000].todense()), \\\n",
    "                    nb_epoch=20, steps_per_epoch=np.shape(train_train_label[0:1000])[0]/20, \\\n",
    "#                     callbacks=[early_stopping, model_checkpoint],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights(bst_model_path) # sotre model parameters in .h5 file\n",
    "bst_val_score = min(hist.history['val_loss'])\n",
    "\n",
    "usr_history[train_train_usr[0:1000],:].todense()\n",
    "\n",
    "# make the prediction\n",
    "print('Start making the submission before fine-tuning')\n",
    "preds = model.predict([data_train_train_one_user[0:1000], usr_history[train_train_usr[0:1000],:].todense()], batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sort_preds = np.argsort(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 33101, 33102, ..., 24851, 47765, 13175],\n",
       "       [    0, 33112, 33113, ..., 21136, 47765, 21902],\n",
       "       [    0, 33116, 33117, ...,  8423, 45006, 21902],\n",
       "       ..., \n",
       "       [    0, 33103, 33104, ..., 13175, 21136, 24851],\n",
       "       [    0, 33113, 33114, ...,   280, 13589, 33197],\n",
       "       [    0, 33106, 33107, ..., 39274, 33547, 24851]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trueth = np.array(train_train_label[0:1000].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   0.00000000e+00,   3.05322826e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         3.17387938e-01,   1.12930842e-01,   2.66003668e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.93589675e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   6.18960410e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.02033801e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         4.89851326e-01,   3.57578173e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   9.47058320e-01,   0.00000000e+00,\n",
       "         1.99050546e-01,   0.00000000e+00,   1.18053926e-01,\n",
       "         0.00000000e+00,   7.96097100e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   4.18209821e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.52314442e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   8.11838368e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         9.35395546e-01,   4.09964204e-01,   0.00000000e+00,\n",
       "         1.38658926e-01,   2.35368978e-01,   2.60287769e-01,\n",
       "         0.00000000e+00,   4.75698639e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.11595827e-01,   5.22622047e-03,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.13293388e-01,\n",
       "         4.05296326e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.02510668e-01,   5.19046709e-02,   2.13057220e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   9.68431085e-02,   0.00000000e+00,\n",
       "         4.70328733e-01,   0.00000000e+00,   3.76710057e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   4.03444558e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.46402507e-02,\n",
       "         4.43386026e-02,   0.00000000e+00,   8.66684839e-02,\n",
       "         0.00000000e+00,   5.84362566e-01,   1.40367866e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   7.23091289e-01,\n",
       "         1.25593007e-01,   2.80225545e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.88391170e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.14049189e-01,\n",
       "         0.00000000e+00,   2.62815267e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.90285671e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   9.00545940e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         3.04149657e-01,   0.00000000e+00,   2.74143219e-01,\n",
       "         5.04741743e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.73801032e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.41366975e-01,\n",
       "         2.92570163e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.56743741e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.27969190e-01,   0.00000000e+00,   1.09016217e-01,\n",
       "         5.14091671e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.38259149e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   4.03572977e-01,\n",
       "         3.82823236e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   5.12972835e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.29942719e-02,   1.64371505e-01,   0.00000000e+00,\n",
       "         8.67290497e-01,   4.23561433e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.00747722e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.04470873e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   4.53534942e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         5.45078479e-02,   0.00000000e+00,   4.80987839e-01,\n",
       "         0.00000000e+00,   6.36542916e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   2.48304978e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.14022821e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.85697669e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   2.55611688e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.31052881e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   2.46077999e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         3.37482542e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   6.79898739e-01,   0.00000000e+00,\n",
       "         7.34948218e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.37398574e-02,   2.63831258e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.64234132e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.51397367e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.61491783e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.60950327e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.70901006e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         9.10302699e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   6.18231893e-01,\n",
       "         4.12705779e-01,   6.11214787e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.29060128e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.18224016e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.77084291e-01,\n",
       "         0.00000000e+00,   1.88443940e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   7.12836757e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.99983165e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         7.19862282e-02,   5.29616382e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   4.64246839e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.53611176e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   2.31094304e-01,   6.10289633e-01,\n",
       "         2.69122541e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         6.73062250e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   4.44261998e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   4.91117937e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.36041297e-02,\n",
       "         5.44030380e-01,   0.00000000e+00,   3.90184259e-01,\n",
       "         4.26940024e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         3.77779871e-01,   5.26171830e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.67528149e-02,\n",
       "         0.00000000e+00,   1.37675226e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.47603624e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.42022665e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   6.11999169e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.75331074e-01,\n",
       "         1.99831307e-01,   0.00000000e+00,   6.10778518e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   8.93935755e-01,\n",
       "         0.00000000e+00,   6.58032224e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   8.84331465e-01,   7.26237390e-02,\n",
       "         5.95589995e-01,   2.27666616e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.34845707e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   4.62734371e-01,\n",
       "         0.00000000e+00,   4.33770426e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   9.89978075e-01,   3.67056131e-02,\n",
       "         2.44503751e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.88919538e-01,\n",
       "         2.20971406e-02,   0.00000000e+00,   1.20056458e-01,\n",
       "         3.56517104e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   6.68923303e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   5.64916134e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   4.70634639e-01,\n",
       "         0.00000000e+00,   2.03821957e-01,   9.69444402e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         4.24419880e-01,   1.12910196e-01,   4.74855782e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   4.69661035e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   9.08820017e-04,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.16865806e+00,   1.26386616e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   9.53908488e-02,\n",
       "         5.26253402e-01,   1.33286966e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.70519012e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.12811494e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         5.82446039e-01,   1.79044791e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   5.53089529e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.65974373e-01,   4.70655084e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.59565860e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.41959578e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.73797324e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.12058550e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   8.17389563e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.95307636e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         5.04784882e-01,   0.00000000e+00,   3.76671851e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.95529366e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   4.99504618e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         3.46775383e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         3.93953383e-01,   9.64975208e-02,   0.00000000e+00,\n",
       "         5.41631281e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.13322306e-01,\n",
       "         0.00000000e+00,   8.83311555e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   8.88184234e-02,   0.00000000e+00,\n",
       "         1.68214366e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.67834538e-01,   5.36188988e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.29042274e-01,\n",
       "         0.00000000e+00,   6.02051735e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.73889151e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   4.12580296e-02,\n",
       "         5.79797566e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.55208141e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         4.92155738e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   8.86544362e-02,   3.49444509e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   8.55989307e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.24510499e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   8.43035519e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.78292215e-01,   4.44983076e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.66016368e-02,   1.06407815e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.47800237e-01,   0.00000000e+00,\n",
       "         8.18469673e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         6.96837947e-01,   0.00000000e+00,   3.41169178e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.92109495e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   9.28537641e-03,   0.00000000e+00,\n",
       "         7.53066927e-01,   0.00000000e+00,   5.05823851e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         3.82596195e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   6.17783085e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.42005771e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.33002447e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.49617928e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   4.70627517e-01,\n",
       "         0.00000000e+00,   3.09069067e-01,   0.00000000e+00,\n",
       "         4.37705934e-01,   0.00000000e+00,   4.02628779e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.64625424e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   7.53821209e-02,\n",
       "         0.00000000e+00,   3.28716010e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   8.92951898e-03,\n",
       "         7.12891296e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.42007682e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   4.78709795e-01,   1.91308148e-02,\n",
       "         0.00000000e+00,   1.16400890e-01,   0.00000000e+00,\n",
       "         3.22102085e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.71432810e-02,\n",
       "         6.16937339e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.49865913e+00,   6.34115279e-01,   5.78660890e-02,\n",
       "         6.90718072e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   9.88424569e-03,\n",
       "         3.44111618e-01,   0.00000000e+00,   7.48239607e-02,\n",
       "         0.00000000e+00,   2.64724955e-01,   0.00000000e+00,\n",
       "         1.20980191e+00,   0.00000000e+00,   2.33088262e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.96815015e-01,   4.10434186e-01,   0.00000000e+00,\n",
       "         8.53260607e-02,   1.44042224e-01,   1.01001412e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         6.33768596e-01,   4.67903679e-03,   0.00000000e+00,\n",
       "         6.05970570e-02,   0.00000000e+00,   4.18465324e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.33241342e-01,\n",
       "         0.00000000e+00,   3.35965689e-01,   4.85551158e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   6.18824199e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.32194935e-02,\n",
       "         2.78755873e-01,   4.73398417e-02,   1.66621730e-01,\n",
       "         0.00000000e+00,   1.18775576e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.81937981e-01,\n",
       "         4.18995410e-01,   7.27455392e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.23591298e-01,   0.00000000e+00,   1.18797093e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.17515279e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.61491290e-01,   4.89268146e-01,   0.00000000e+00,\n",
       "         1.87083295e-01,   0.00000000e+00,   3.31213504e-01,\n",
       "         0.00000000e+00,   9.36056674e-02,   0.00000000e+00,\n",
       "         2.14369893e-01,   2.46267438e-01,   3.27899247e-01,\n",
       "         1.64902702e-01,   1.20682508e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.33142620e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   7.74398632e-03,   1.16915178e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.64058827e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.69378902e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.95810031e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.98717520e-01,   0.00000000e+00,\n",
       "         0.00000000e+00])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trueth * preds).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 33101, 33102, ..., 24851, 47765, 13175],\n",
       "       [    0, 33112, 33113, ..., 21136, 47765, 21902],\n",
       "       [    0, 33116, 33117, ...,  8423, 45006, 21902],\n",
       "       ..., \n",
       "       [    0, 33103, 33104, ..., 13175, 21136, 24851],\n",
       "       [    0, 33113, 33114, ...,   280, 13589, 33197],\n",
       "       [    0, 33106, 33107, ..., 39274, 33547, 24851]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91256803"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
